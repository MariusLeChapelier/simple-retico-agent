import datetime
from TTS.api import TTS
import numpy as np
import scipy.io.wavfile

names = [
    "tts_models/en/jenny/jenny",
    "tts_models/en/ljspeech/vits",
    "tts_models/en/ljspeech/vits--neon",
    "tts_models/en/ljspeech/fast_pitch",  # bug sometimes
    "tts_models/en/vctk/vits",
]
m_name = names[0]
model = TTS(m_name).to("cuda")
frame_duration = 0.2
samplerate = model.synthesizer.tts_config.get("audio")["sample_rate"]
chunk_size = int(samplerate * frame_duration)
chunk_size_bytes = chunk_size * 2
print("samplerate = ", samplerate)
print("samplerate = ", chunk_size)
print("samplerate = ", chunk_size_bytes)

bc_text = [
    "My name is Marius, How are you today ? that's wonderful to hear! Alright then, let's get started with our math lesson today. Do you remember what we learned about addition in our previous class? "
]

# bc_text = [
#     "Hello there! I'm doing well, thank you. And how about you, little one? How did your day go so far?"
# ]
# bc_text = [
#     "Hello there!",
#     "I'm doing well,",
#     "thank you.",
#     "And how about you,",
#     "little one?",
#     "How did your day go so far?",
# ]
# bc_text = ["Yeah !"]
# bc_text = [
#     "Yeah !",
#     "okay",
#     "alright",
#     "Yeah, okay.",
#     "uh",
#     "uh, okay",
# ]

for i, t in enumerate(bc_text):
    print(f"start : {datetime.datetime.now()}")
    waveforms, outputs = model.tts(
        text=t,
        # speaker="p225",
        return_extra_outputs=True,
        split_sentences=False,
        verbose=True,
    )
    print(f"end : {datetime.datetime.now()}")
    print(len(outputs))
    print(len(waveforms))
    print(len(outputs[0]["wav"]))

    chunk = (np.array(outputs[0]["wav"]) * 32767).astype(np.int16).tobytes()
    print(f"conversion : {datetime.datetime.now()}")
    print(len(chunk))

    # print(waveforms)
    for j, o in enumerate(outputs):
        scipy.io.wavfile.write(
            f"audios/test_tts/test_{i}_{j}.wav",
            samplerate,
            o["wav"],
        )


# model.cuda()

# model.tts_to_file(
#     text=text,
#     speaker="p225",
#     return_extra_outputs=True,
#     split_sentences=False,
#     verbose=True,
#     file_path="test_tts.wav",
# )

# (np.array(chunk) * 32767).astype(np.int16).tobytes()


# self.samplerate = self.model.synthesizer.tts_config.get("audio")["sample_rate"]
# self.chunk_size = int(self.samplerate * self.frame_duration)
# self.chunk_size_bytes = self.chunk_size * self.samplewidth


def get_new_iu_buffer_from_clause_ius(
    current_text, multi, model, frame_duration, samplerate, chunk_size, chunk_size_bytes
):
    """Function that aligns the TTS inputs and outputs.
    It links the words sent by LLM to audio chunks generated by TTS model.
    As we have access to the durations of the phonems generated by the model,
    we can link the audio chunks sent to speaker to the words that it corresponds to.

    Returns:
        list[TextAlignedAudioIU]: the TextAlignedAudioIUs that will be sent to the speaker module, containing the correct informations about grounded_iu, turn_id or char_id.
    """
    # preprocess on words
    words = [" " + w for w in current_text.split(" ")]
    # current_text = "".join(words)
    print(f"words {words}")
    pre_pro_words = []
    pre_pro_words_distinct = []
    for i, w in enumerate(words):
        if w[0] == " ":
            pre_pro_words.append(i - 1)
            if len(pre_pro_words) >= 2:
                pre_pro_words_distinct.append(
                    words[pre_pro_words[-2] + 1 : pre_pro_words[-1] + 1]
                )
            else:
                pre_pro_words_distinct.append(words[: pre_pro_words[-1] + 1])
    pre_pro_words.pop(0)
    pre_pro_words.append(len(words) - 1)
    pre_pro_words_distinct.pop(0)

    if len(pre_pro_words) >= 2:
        pre_pro_words_distinct.append(
            words[pre_pro_words[-2] + 1 : pre_pro_words[-1] + 1]
        )
    else:
        pre_pro_words_distinct.append(words[: pre_pro_words[-1] + 1])

    # print(f"before_synthesize : {datetime.datetime.now()}")
    if multi:
        new_audio, final_outputs = model.tts(
            text=current_text,
            speaker="p225",
            return_extra_outputs=True,
            split_sentences=False,
            verbose=True,
        )
    else:
        new_audio, final_outputs = model.tts(
            text=current_text,
            return_extra_outputs=True,
            split_sentences=False,
            verbose=True,
        )

    # hard coded values for the TTS model found in CoquiTTS github repo or calculated
    # s = model.synthesizer.tts_model.tokenizer.text_to_ids(" ")
    s2 = model.synthesizer.tts_model.tokenizer.encode(" ")[0]
    print(f"space tokens = {s2}")
    # SPACE_TOKEN_ID = 16
    SPACE_TOKEN_ID = s2
    NB_FRAME_PER_DURATION = 256 if multi else 512

    # print(f"after_synthesize : {datetime.datetime.now()}")
    tokens = model.synthesizer.tts_model.tokenizer.text_to_ids(current_text)
    print(f"tokens = {tokens}")
    # print(f"alignement : {datetime.datetime.now()}")
    space_tokens_ids = []
    for i, x in enumerate(tokens):
        if x == SPACE_TOKEN_ID or i == len(tokens) - 1:
            space_tokens_ids.append(i + 1)

    print(f"space_tokens_ids = {space_tokens_ids}")

    new_buffer = []
    for outputs in final_outputs:
        len_wav = len(outputs["wav"])
        durations = outputs["outputs"]["durations"].squeeze().tolist()
        # total_duration = int(sum(durations))

        wav_words_chunk_len = []
        old_len_w = 0
        for s_id in space_tokens_ids:
            wav_words_chunk_len.append(
                int(sum(durations[old_len_w:s_id])) * NB_FRAME_PER_DURATION
            )
            # wav_words_chunk_len.append(int(sum(durations[old_len_w:s_id])) * len_wav / total_duration )
            old_len_w = s_id

        cumsum_wav_words_chunk_len = list(np.cumsum(wav_words_chunk_len))
        print(f"cumsum_wav_words_chunk_len = {cumsum_wav_words_chunk_len}")
        print(f"len wav = {len_wav}")
        i = 0
        j = 0
        total_audio = b""
        while i < len_wav:
            chunk = outputs["wav"][i : i + chunk_size]
            # modify raw audio to match correct format
            chunk = (np.array(chunk) * 32767).astype(np.int16).tobytes()
            ## TODO : change that silence padding: padding with silence will slow down the speaker a lot
            word_id = pre_pro_words[-1]
            if len(chunk) < chunk_size_bytes:
                chunk = chunk + b"\x00" * (chunk_size_bytes - len(chunk))
            else:
                while i + chunk_size >= cumsum_wav_words_chunk_len[j]:
                    j += 1
                if j < len(pre_pro_words):
                    word_id = pre_pro_words[j]

            temp_word = words[word_id]
            words_until_word_id = words[: word_id + 1]
            len_words = [len(word) for word in words[: word_id + 1]]
            char_id = sum(len_words) - 1

            i += chunk_size
            total_audio += chunk

    return new_buffer


# t = "My name is Marius, How are you today ? that's wonderful to hear! Alright then, let's get started with our math lesson today. Do you remember what we learned about addition in our previous class? "
# get_new_iu_buffer_from_clause_ius(t)

bc_text = [
    "Hello there!",
    "I'm doing well,",
    "thank you.",
    "And how about you,",
    "little one?",
    "How did your day go so far?",
]


##
# names = [
#     "tts_models/en/vctk/vits",
# ]
# names_2 = [
#     "tts_models/en/jenny/jenny",
#     "tts_models/en/ljspeech/vits",
#     "tts_models/en/ljspeech/vits--neon",
#     # "tts_models/en/ljspeech/fast_pitch",  # bug sometimes
# ]
# for m in names:
#     model = TTS(m).to("cuda")
#     frame_duration = 0.2
#     samplerate = model.synthesizer.tts_config.get("audio")["sample_rate"]
#     chunk_size = int(samplerate * frame_duration)
#     chunk_size_bytes = chunk_size * 2
#     print("samplerate = ", samplerate)
#     print("samplerate = ", chunk_size)
#     print("samplerate = ", chunk_size_bytes)

#     before = datetime.datetime.now()
#     for t in bc_text:
#         get_new_iu_buffer_from_clause_ius(
#             t, True, model, frame_duration, samplerate, chunk_size, chunk_size_bytes
#         )
#     after = datetime.datetime.now()

#     print(f"duration = {after-before}")

# for m in names_2:
#     model = TTS(m).to("cuda")
#     frame_duration = 0.2
#     samplerate = model.synthesizer.tts_config.get("audio")["sample_rate"]
#     chunk_size = int(samplerate * frame_duration)
#     chunk_size_bytes = chunk_size * 2
#     print("samplerate = ", samplerate)
#     print("samplerate = ", chunk_size)
#     print("samplerate = ", chunk_size_bytes)

#     before = datetime.datetime.now()
#     for t in bc_text:
#         get_new_iu_buffer_from_clause_ius(
#             t, False, model, frame_duration, samplerate, chunk_size, chunk_size_bytes
#         )
#     after = datetime.datetime.now()

#     print(f"duration = {after-before}")

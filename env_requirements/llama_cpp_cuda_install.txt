# Windows
$env:CMAKE_ARGS = "-DLLAMA_BLAS=ON"
pip install llama-cpp-python

set FORCE_CMAKE=1 && set CMAKE_ARGS=-DLLAMA_CUBLAS=on -DLLAMA_AVX=off -DLLAMA_AVX2=off -DLLAMA_FMA=off
pip install llama-cpp-python --no-cache-dir

set CMAKE_ARGS=-DLLAMA_CUBLAS=on
pip install llama-cpp-python --no-cache-dir


# command to enable cuda with llama-cpp-python :
pip uninstall llama-cpp-python && set "CMAKE_ARGS=-DLLAMA_CUBLAS=on" && pip install llama-cpp-python --no-cache-dir

set "CMAKE_ARGS=-DLLAMA_CUBLAS=on -DLLAMA_AVX=off -DLLAMA_AVX2=off -DLLAMA_FMA=off" && pip install llama-cpp-python --no-cache-dir

# conda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=11.8 -c pytorch -c nvidia
# nvidia cuda 11.6.134 driver


pip uninstall llama-cpp-python && set "CMAKE_ARGS=-DGGML_CUDA=on" && pip install llama-cpp-python --no-cache-dir